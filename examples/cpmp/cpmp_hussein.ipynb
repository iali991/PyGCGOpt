{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ea1623",
   "metadata": {},
   "source": [
    "# Decomposing the Capacitated p-Median Problem\n",
    "The capacitated p-median problem (CPMP) is a known and well-studied problem from the literature. Given\n",
    "$n \\in \\mathbb{N}$ locations, the task is to select $p \\in \\mathbb{N}$ *median* locations with $p \\leq n$ and to\n",
    "assign each location to exactly one median. For any two locations $i,j \\in [n]$, the distance between them is given\n",
    "by $d_{ij} \\in \\mathbb{R}$. The distance between the locations and their assigned medians is minimized. Every\n",
    "location $i \\in [n]$ has a *demand* $q_i \\in \\mathbb{R}$ and a maximum *capacity* $Q_i \\in \\mathbb{R}$. For every\n",
    "selected median, the sum of the demands of the locations assigned to it must not exceed its capacity.\n",
    "\n",
    "The CPMP can be formulated as a MIP. Here is a classical compact formulation of problem:\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{3}\n",
    "z^{\\star}_{IP}\\,\\,\\,=\\,\\,\\,\\min{} &\\sum_{i=1}^n \\sum_{j=1}^n d_{ij} x_{ij} \\hspace{-2em} &&&&\\\\\n",
    "                     \\text{s. t.} &\\sum_{j=1}^n  x_{ij} &&= 1 \\quad &\\forall i &\\in [n]\\\\\n",
    "                                  &\\sum_{i=1}^{n} q_i x_{ij} &&\\leq Q_j y_j \\quad &\\forall j &\\in [n] \\\\\n",
    "                                  &\\sum_{j=1}^n  y_j &&= p && \\\\\n",
    "                                  &x_{ij} \\in \\{0,1\\}, y_j \\in \\{0,1\\} \\hspace{-6em} &&\\hspace{6em}\\quad& \\forall i,j &\\in [n].\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "There are different approaches to solve the CPMP. As it has a structure, we can try to solve using a\n",
    "Branch-Cut-and-Price approach. For that we want to use the `PyGCGOpt` interface to interact with GCG. We will consider three\n",
    "use-cases: (1) The Automatic Mode, (2) Exploring different Decompositions, and (3) Building a custom Decomposition.\n",
    "\n",
    "To follow along with this tutorial interactively, please download the Jupyter notebook from the [examples folder](https://github.com/scipopt/PyGCGOpt/tree/master/examples/cpmp)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bfbf84",
   "metadata": {},
   "source": [
    "## Reading in the Instance\n",
    "The `PyGCGOpt` interface offers two methods to specify a problem. The first is to load the model from a standardized file format (e.g., `.lp` or `.mps`) that is supported by `SCIP` using `Model.readProb()`. Optionally, one can also read in a decomposition from a `.dec` file in the same manner. In this example, we will use the second method: Modeling a problem directly in Python.\n",
    "\n",
    "Execute the following cell which includes a trivial test instance and function to load more instances from a custom `JSON` file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "joint-colony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pygcgopt\n",
    "print(pygcgopt.__version__)\n",
    "def get_simple_instance():\n",
    "    n = 5\n",
    "    p = 2\n",
    "    d = {0: {0: 0, 1: 25, 2: 46, 3: 43, 4: 30}, 1: {1: 0, 2: 22, 3: 20, 4: 22}, 2: {2: 0, 3: 22, 4: 40}, 3: {3: 0, 4: 22}, 4: {4: 0}}\n",
    "    q = {0: 14, 1: 13, 2: 9, 3: 15, 4: 6}\n",
    "    Q = {i: 33 for i in range(5)}\n",
    "    return n, p, d, q, Q\n",
    "\n",
    "def read_instance_json(path):\n",
    "    with open(path) as f:\n",
    "        instance = json.load(f)\n",
    "    d = {int(k): {int(kk): vv for kk, vv in v.items()} for k, v in instance[\"d\"].items()}\n",
    "    q = {int(k): v for k, v in instance[\"q\"].items()}\n",
    "    Q = {int(k): v for k, v in instance[\"Q\"].items()}\n",
    "    return instance[\"n\"], instance[\"p\"], d, q, Q\n",
    "\n",
    "n_locations, n_clusters, distances, demands, capacities = read_instance_json(\"instances/p550-01.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ffb130",
   "metadata": {},
   "source": [
    "## Setting up the Model\n",
    "Now, we want to build the model based on the above formulation. Please note that this part is *not* specific to GCG but is identical to how one would build the same model with `PySCIPOpt`. In technical terms, `Model` in `PyGCGOpt` is a subclass of `Model`  in `PySCIPOpt` and, therefore, you can use all methods of `PySCIPOpt` `Model` to build your problem.\n",
    "\n",
    "In order to recreate the model multiple times during this example, we create a method that will return the model. The method also returns the different constraints added to the model grouped by type. This will be important later in use-case 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ffa8aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygcgopt import Model, quicksum\n",
    "\n",
    "\n",
    "def build_model(n_locations, n_clusters, distances, demands, capacities):\n",
    "    m = Model()\n",
    "\n",
    "    m.printVersion()\n",
    "    m.redirectOutput()\n",
    "\n",
    "    m.setMinimize()\n",
    "\n",
    "    x = {}\n",
    "    y = {}\n",
    "\n",
    "    for j in range(n_locations):\n",
    "        y[j] = m.addVar(f\"y_{j}\", vtype=\"B\")\n",
    "        for i in range(n_locations):\n",
    "            x[i, j] = m.addVar(f\"x_{i}_{j}\", vtype=\"B\", obj=distances[min(i,j)][max(i,j)])\n",
    "\n",
    "    # Hold different constraint types\n",
    "    conss_assignment = []\n",
    "    conss_capacity = []\n",
    "    cons_pmedian = None\n",
    "\n",
    "    # Create the assignment constraints\n",
    "    for i in range(n_locations):\n",
    "        conss_assignment.append(\n",
    "            m.addCons(quicksum(x[i, j] for j in range(n_locations)) == 1)\n",
    "        )\n",
    "\n",
    "    # Create the capacity constraints\n",
    "    for j in range(n_locations):\n",
    "        conss_capacity.append(\n",
    "            m.addCons(quicksum(demands[i] * x[i, j] for i in range(n_locations)) <= capacities[j] * y[j])\n",
    "        )\n",
    "\n",
    "    # Create the p-median constraint\n",
    "    cons_pmedian = m.addCons(quicksum(y[j] for j in range(n_locations)) == n_clusters)\n",
    "\n",
    "    return m, conss_assignment, conss_capacity, cons_pmedian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1dd31f",
   "metadata": {},
   "source": [
    "## Use-Case 1: The Automatic Mode\n",
    "With the model built, we can now simply call the `optimize()` function and let GCG do its magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "selected-ticket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCG version 3.6.2 [GitHash: NoGitInfo]\n",
      "Copyright (C) 2010-2024 Operations Research, RWTH Aachen University\n",
      "                        Konrad-Zuse-Zentrum fuer Informationstechnik Berlin (ZIB)\n",
      "\n",
      "SCIP version 9.1.1 [precision: 8 byte] [memory: block] [mode: optimized] [LP solver: Soplex 7.1.1] [GitHash: NoGitInfo]\n",
      "Copyright (c) 2002-2024 Zuse Institute Berlin (ZIB)\n",
      "presolving:\n",
      "(round 1, exhaustive) 0 del vars, 0 del conss, 0 add conss, 0 chg bounds, 0 chg sides, 0 chg coeffs, 100 upgd conss, 0 impls, 50 clqs\n",
      "   (0.0s) probing: 51/2550 (2.0%) - 0 fixings, 0 aggregations, 0 implications, 0 bound changes\n",
      "   (0.0s) probing aborted: 50/50 successive totally useless probings\n",
      "presolving (2 rounds: 2 fast, 2 medium, 2 exhaustive):\n",
      " 0 deleted vars, 0 deleted constraints, 0 added constraints, 0 tightened bounds, 0 added holes, 0 changed sides, 0 changed coefficients\n",
      " 0 implications, 2550 cliques\n",
      "presolved problem has 2550 variables (2550 bin, 0 int, 0 impl, 0 cont) and 101 constraints\n",
      "     50 constraints of type <knapsack>\n",
      "     50 constraints of type <setppc>\n",
      "      1 constraints of type <linear>\n",
      "transformed objective value is always integral (scale: 1)\n",
      "Presolving Time: 0.03\n",
      " Consclassifier \"nonzeros\" yields a classification with 2  different constraint classes \n",
      " Consclassifier \"constypes\" yields a classification with 3 different constraint classes \n",
      " Consclassifier \"constypes according to miplib\" yields a classification with 3 different constraint classes \n",
      " Conspartition \"constypes according to miplib\" is not considered since it offers the same structure as \"constypes\" conspartition\n",
      " Consclassifier \"gamsdomain\" yields a classification with 1  different constraint classes \n",
      " Consclassifier \"gamssymbols\" yields a classification with 1  different constraint classes \n",
      " Conspartition \"gamssymbols\" is not considered since it offers the same structure as \"gamsdomain\" conspartition\n",
      " Varclassifier \"gamsdomain\" yields a classification with 1  different variable classes \n",
      " Varclassifier \"gamssymbols\" yields a classification with 1  different variable classes \n",
      " Varpartition \"gamssymbols\" is not considered since it offers the same structure as \"gamsdomain\"\n",
      " Varclassifier \"vartypes\" yields a classification with 1 different variable classes\n",
      " Varpartition \"vartypes\" is not considered since it offers the same structure as \"gamsdomain\"\n",
      " Varclassifier \"varobjvals\" yields a classification with 116 different variable classes\n",
      " Varclassifier \"varobjvalsigns\" yields a classification with 2 different variable classes\n",
      " the current varclass distribution includes 116 classes but only 18 are allowed for GCGconshdlrDecompCalcCandidatesNBlocks()\n",
      " in dec_consclass: there are 3 different constraint classes   \n",
      "  the current constraint classifier \"nonzeros\" consists of 2 different classes   \n",
      "  the current constraint classifier \"constypes\" consists of 3 different classes   \n",
      "  the current constraint classifier \"gamsdomain\" consists of 1 different classes   \n",
      " dec_consclass found 11 new partialdecs \n",
      "dec_densemasterconss found 1 new partialdec \n",
      "dec_neighborhoodmaster found 1 new partialdec \n",
      "POSTPROCESSING of decompositions. Added 0 new decomps. \n",
      "Found 11 finished decompositions.\n",
      "Measured running time per detector:\n",
      "Detector consclass                 worked on        7 finished decompositions and took a total time of      0.000\n",
      "Detector neighborhoodmaster        worked on        1 finished decompositions and took a total time of      0.000\n",
      "Detector connectedbase             worked on       10 finished decompositions and took a total time of      0.003\n",
      "Detector varclass                  worked on        2 finished decompositions and took a total time of      0.000\n",
      "Detection Time: 0.01\n",
      " the current varclass distribution includes 116 classes but only 9 are allowed for propagatePartialdec() of var class detector\n",
      "\n",
      "A Dantzig-Wolfe reformulation is applied to solve the original problem.\n",
      "Chosen structure has 50 blocks and 51 linking constraints.\n",
      "This decomposition has a maxwhite score of 0.485149.\n",
      "Matrix has 50 blocks, using 50 pricing problems.\n",
      "\n",
      "  time | node  | left  |SLP iter|MLP iter|LP it/n| mem |mdpt |ovars|mvars|ocons|mcons|mcuts|  dualbound   | primalbound  |  deg   |  gap   \n",
      "p  0.1s|     1 |     0 |      0 |      0 |     - |  36M|   0 |2550 |   0 | 102 |   0 |   0 | 0.000000e+00 | 2.711000e+03 |   --   |    Inf \n",
      "p  0.2s|     1 |     0 |      0 |      0 |     - |  36M|   0 |2550 |   0 | 102 |   0 |   0 | 0.000000e+00 | 1.785000e+03 |   --   |    Inf \n",
      "p  0.2s|     1 |     0 |      0 |      0 |     - |  36M|   0 |2550 |   0 | 102 |   0 |   0 | 0.000000e+00 | 1.102000e+03 |   --   |    Inf \n",
      "   0.2s|     1 |     0 |      0 |      0 |     - |  36M|   0 |2550 |   0 | 102 |   0 |   0 | 0.000000e+00 | 1.102000e+03 |   --   |    Inf \n",
      "\n",
      "   0.2s|     1 |     0 |      0 |      0 |     - |  36M|   0 |2550 |  50 | 102 | 102 |   0 | 0.000000e+00 | 1.102000e+03 |   0.00%|    Inf    0.2s|     1 |     0 |      0 |      0 |     - |  36M|   0 |2550 | 150 | 102 | 102 |   0 | 0.000000e+00 | 1.102000e+03 |   0.00%|    Inf    0.4s|     1 |     0 |   2081 |   2081 |     - |  44M|   0 |2550 |1699 | 102 | 102 |   0 | 7.050000e+02 | 1.102000e+03 |  36.95%|  56.31%     \n",
      "X  1.3s|     1 |     0 |   3055 |   3055 |     - |  55M|   0 |2550 |1749 | 102 | 102 |   0 | 7.050000e+02 | 8.150000e+02 |  36.95%|  15.60%\n",
      "Y  1.3s|     1 |     0 |   3055 |   3055 |     - |  55M|   0 |2550 |1799 | 102 | 102 |   0 | 7.050000e+02 | 7.580000e+02 |  36.95%|   7.52%\n",
      "   1.3s|     1 |     0 |   3055 |   3055 |     - |  55M|   0 |2550 |1799 | 102 | 102 |   0 | 7.050000e+02 |\n",
      "\n",
      "Starting reduced cost pricing...\n",
      "\n",
      " 7.580000e+02 |  36.95%|   7.52%\n",
      "   1.3s|     1 |     0 |   3055 |   3055 |     - |  55M|   0 |2550 |1799 | 102 | 102 |   0 | 7.050000e+02 | 7.580000e+02 |  36.95%|   7.52%\n",
      "   1.3s|     1 |     0 |   3055 |   3055 |     - |  55M|   0 |2550 |1799 | 102 | 102 |   0 | 7.050000e+02 | 7.580000e+02 |  36.95%|   7.52%\n",
      "   1.3s|     1 |     2 |   3055 |   3055 |     - |  55M|   0 |2550 |1799 | 102 | 102 |   0 | 7.050000e+02 | 7.580000e+02 |  36.95%|   7.52%\n",
      "*r 2.5s|     6 |     5 |   4384 |   4384 | 327.4 | 156M|   3 |2550 |2002 | 102 | 102 |   0 | 7.065000e+02 | 7.380000e+02 |   --   |   4.46%\n",
      "*r 2.5s|     6 |     5 |   4482 |   4482 | 347.0 | 156M|   3 |2550 |2053 | 102 | 102 |   0 | 7.065000e+02 | 7.340000e+02 |   --   |   3.89%\n",
      "  time | node  | left  |SLP iter|MLP iter|LP it/n| mem |mdpt |ovars|mvars|ocons|mcons|mcuts|  dualbound   | primalbound  |  deg   |  gap   \n",
      "*r 3.8s|    21 |     8 |  10404 |  10404 | 382.9 | 159M|   5 |2550 |2270 | 102 | 102 |   0 | 7.123333e+02 | 7.150000e+02 |   --   |   0.37%\n",
      "*r 3.8s|    22 |     5 |  10466 |  10466 | 367.6 | 159M|   6 |2550 |2270 | 102 | 102 |   0 | 7.123333e+02 | 7.140000e+02 |   --   |   0.23%\n",
      "*r 3.9s|    22 |     0 |  10699 |  10699 | 378.7 | 160M|   6 |2550 |2461 | 102 | 102 |   0 | 7.123333e+02 | 7.130000e+02 |   --   |   0.09%\n",
      "\n",
      "SCIP Status        : problem is solved [optimal solution found]\n",
      "Solving Time (sec) : 3.90\n",
      "Solving Nodes      : 22\n",
      "Primal Bound       : +7.13000000000000e+02 (11 solutions)\n",
      "Dual Bound         : +7.13000000000000e+02\n",
      "Gap                : 0.00 %\n"
     ]
    }
   ],
   "source": [
    "m, *conss = build_model(n_locations, n_clusters, distances, demands, capacities)\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4b2a1",
   "metadata": {},
   "source": [
    "## Use-Case 2: Exploring different Decompositions\n",
    "Above, we have seen GCG in its fully automatic mode. If we want to dig deeper, we can inspect the different decompositions that GCG detects. For that, we recreate the model and manually execute `presolve()` and `detect()` for the model. At this stage it is possible to list and visualize the found decompositions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "satisfactory-convertible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCG version 3.6.2 [GitHash: NoGitInfo]\n",
      "Copyright (C) 2010-2024 Operations Research, RWTH Aachen University\n",
      "                        Konrad-Zuse-Zentrum fuer Informationstechnik Berlin (ZIB)\n",
      "\n",
      "SCIP version 9.1.1 [precision: 8 byte] [memory: block] [mode: optimized] [LP solver: Soplex 7.1.1] [GitHash: NoGitInfo]\n",
      "Copyright (c) 2002-2024 Zuse Institute Berlin (ZIB)\n",
      "presolving:\n",
      "(round 1, exhaustive) 0 del vars, 0 del conss, 0 add conss, 0 chg bounds, 0 chg sides, 0 chg coeffs, 100 upgd conss, 0 impls, 50 clqs\n",
      "   (0.0s) probing: 51/2550 (2.0%) - 0 fixings, 0 aggregations, 0 implications, 0 bound changes\n",
      "   (0.0s) probing aborted: 50/50 successive totally useless probings\n",
      "presolving (2 rounds: 2 fast, 2 medium, 2 exhaustive):\n",
      " 0 deleted vars, 0 deleted constraints, 0 added constraints, 0 tightened bounds, 0 added holes, 0 changed sides, 0 changed coefficients\n",
      " 0 implications, 2550 cliques\n",
      "presolved problem has 2550 variables (2550 bin, 0 int, 0 impl, 0 cont) and 101 constraints\n",
      "     50 constraints of type <knapsack>\n",
      "     50 constraints of type <setppc>\n",
      "      1 constraints of type <linear>\n",
      "transformed objective value is always integral (scale: 1)\n",
      "Presolving Time: 0.03\n",
      "starting detection\n",
      " Consclassifier \"nonzeros\" yields a classification with 2  different constraint classes \n",
      " Consclassifier \"constypes\" yields a classification with 3 different constraint classes \n",
      " Consclassifier \"constypes according to miplib\" yields a classification with 3 different constraint classes \n",
      " Conspartition \"constypes according to miplib\" is not considered since it offers the same structure as \"constypes\" conspartition\n",
      " Consclassifier \"gamsdomain\" yields a classification with 1  different constraint classes \n",
      " Consclassifier \"gamssymbols\" yields a classification with 1  different constraint classes \n",
      " Conspartition \"gamssymbols\" is not considered since it offers the same structure as \"gamsdomain\" conspartition\n",
      " Varclassifier \"gamsdomain\" yields a classification with 1  different variable classes \n",
      " Varclassifier \"gamssymbols\" yields a classification with 1  different variable classes \n",
      " Varpartition \"gamssymbols\" is not considered since it offers the same structure as \"gamsdomain\"\n",
      " Varclassifier \"vartypes\" yields a classification with 1 different variable classes\n",
      " Varpartition \"vartypes\" is not considered since it offers the same structure as \"gamsdomain\"\n",
      " Varclassifier \"varobjvals\" yields a classification with 116 different variable classes\n",
      " Varclassifier \"varobjvalsigns\" yields a classification with 2 different variable classes\n",
      " the current varclass distribution includes 116 classes but only 18 are allowed for GCGconshdlrDecompCalcCandidatesNBlocks()\n",
      " in dec_consclass: there are 3 different constraint classes   \n",
      "  the current constraint classifier \"nonzeros\" consists of 2 different classes   \n",
      "  the current constraint classifier \"constypes\" consists of 3 different classes   \n",
      "  the current constraint classifier \"gamsdomain\" consists of 1 different classes   \n",
      " dec_consclass found 11 new partialdecs \n",
      "dec_densemasterconss found 1 new partialdec \n",
      "dec_neighborhoodmaster found 1 new partialdec \n",
      "POSTPROCESSING of decompositions. Added 0 new decomps. \n",
      "Found 11 finished decompositions.\n",
      "Measured running time per detector:\n",
      "Detector consclass                 worked on        7 finished decompositions and took a total time of      0.000\n",
      "Detector neighborhoodmaster        worked on        1 finished decompositions and took a total time of      0.000\n",
      "Detector connectedbase             worked on       10 finished decompositions and took a total time of      0.003\n",
      "Detector varclass                  worked on        2 finished decompositions and took a total time of      0.000\n",
      "Detection Time: 0.01\n",
      " the current varclass distribution includes 116 classes but only 9 are allowed for propagatePartialdec() of var class detector\n",
      "GCG found 11 finnished decompositions.\n"
     ]
    }
   ],
   "source": [
    "m, *conss = build_model(n_locations, n_clusters, distances, demands, capacities)\n",
    "m.presolve()\n",
    "m.detect()\n",
    "\n",
    "decomps = m.listDecompositions()\n",
    "\n",
    "print(\"GCG found {} finnished decompositions.\".format(len(decomps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ab777",
   "metadata": {},
   "source": [
    "### Inspecting Decompositions\n",
    "\n",
    "The call to `listDecompositions()` returns a list of `PartialDecomposition` objects. We can print a decomposition using the Python `print()` function to get a summary or access different fields directly.\n",
    "\n",
    "For a full overview of available methods, take a look at the online documentation for the `PartialDecomposition` class, or execute `help(d)` where `d` is a decomposition object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accepting-magnet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of decompositions: 11\n",
      "\n",
      "Decomposition 0 scores:\n",
      "Classic score: 1.0000\n",
      "Border area score: 0.0000\n",
      "Max white score: 0.0000\n",
      "Max for white score: 0.0000\n",
      "\n",
      "Decomposition 1 scores:\n",
      "Classic score: 0.7040\n",
      "Border area score: 1.0000\n",
      "Max white score: 0.0000\n",
      "Max for white score: 0.0000\n",
      "\n",
      "Decomposition 2 scores:\n",
      "Classic score: 0.5970\n",
      "Border area score: 0.4950\n",
      "Max white score: 0.4851\n",
      "Max for white score: 0.4851\n",
      "\n",
      "Decomposition 3 scores:\n",
      "Classic score: 0.6030\n",
      "Border area score: 0.5050\n",
      "Max white score: 0.4950\n",
      "Max for white score: 0.4950\n",
      "\n",
      "Decomposition 4 scores:\n",
      "Classic score: 0.4070\n",
      "Border area score: 0.5050\n",
      "Max white score: 0.0000\n",
      "Max for white score: 0.0000\n",
      "\n",
      "Decomposition 5 scores:\n",
      "Classic score: 0.3001\n",
      "Border area score: 0.0099\n",
      "Max white score: 0.0097\n",
      "Max for white score: 0.0097\n",
      "\n",
      "Decomposition 6 scores:\n",
      "Classic score: 0.6980\n",
      "Border area score: 0.9901\n",
      "Max white score: 0.0000\n",
      "Max for white score: 0.0000\n",
      "\n",
      "Decomposition 7 scores:\n",
      "Classic score: 0.5912\n",
      "Border area score: 0.4950\n",
      "Max white score: 0.4853\n",
      "Max for white score: 0.4853\n",
      "\n",
      "Decomposition 8 scores:\n",
      "Classic score: 0.6980\n",
      "Border area score: 0.9901\n",
      "Max white score: 0.0000\n",
      "Max for white score: 0.0000\n",
      "\n",
      "Decomposition 9 scores:\n",
      "Classic score: 0.3000\n",
      "Border area score: 0.0000\n",
      "Max white score: 0.0000\n",
      "Max for white score: 0.0193\n",
      "\n",
      "Decomposition 10 scores:\n",
      "Classic score: 1.0000\n",
      "Border area score: 0.0000\n",
      "Max white score: 0.0000\n",
      "Max for white score: 0.0000\n",
      "\n",
      "Selected decomposition scores: d.classic_score=0.5970, d.border_area_score=0.4950, d.max_white_score=0.4851, d.max_for_white_score=0.4851\n"
     ]
    }
   ],
   "source": [
    "# Instead of print(decomps), let's print each decomposition's scores explicitly\n",
    "print(f\"\\nNumber of decompositions: {len(decomps)}\")\n",
    "for i, dec in enumerate(decomps):\n",
    "    print(f\"\\nDecomposition {i} scores:\")\n",
    "    print(f\"Classic score: {dec.classic_score:.04f}\")\n",
    "    print(f\"Border area score: {dec.border_area_score:.04f}\")\n",
    "    print(f\"Max white score: {dec.max_white_score:.04f}\")\n",
    "    print(f\"Max for white score: {dec.max_for_white_score:.04f}\")\n",
    "\n",
    "# Then continue with selecting decomposition 2\n",
    "d = decomps[2]\n",
    "print(\n",
    "    f\"\\nSelected decomposition scores: {d.classic_score=:.04f}, {d.border_area_score=:.04f}, {d.max_white_score=:.04f}, {d.max_for_white_score=:.04f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c54bd",
   "metadata": {},
   "source": [
    "### Visualizing Decompositions\n",
    "In addition, GCG can create graphical visualizations of decompositions. They can easily be displayed in a Jupyter nodebook like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0955eaa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'pygcgopt.gcg.PartialDecomposition' object has no attribute 'maxForWhiteScore'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/gcg-env/lib/python3.8/site-packages/IPython/core/formatters.py:708\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    701\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[1;32m    702\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[1;32m    704\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[1;32m    705\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[1;32m    706\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[1;32m    707\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 708\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/miniconda3/envs/gcg-env/lib/python3.8/site-packages/IPython/lib/pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    408\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \\\n\u001b[1;32m    409\u001b[0m                         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m--> 410\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gcg-env/lib/python3.8/site-packages/IPython/lib/pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[0;32msrc/pygcgopt/decomposition.pxi:1433\u001b[0m, in \u001b[0;36mpygcgopt.gcg.PartialDecomposition.__repr__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'pygcgopt.gcg.PartialDecomposition' object has no attribute 'maxForWhiteScore'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: gnuplot: not found\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/tmplxh7_wqc/vis.svg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/gcg-env/lib/python3.8/site-packages/IPython/core/formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    342\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32msrc/pygcgopt/decomposition.pxi:1395\u001b[0m, in \u001b[0;36mpygcgopt.gcg.PartialDecomposition._repr_svg_\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/pygcgopt/decomposition.pxi:1406\u001b[0m, in \u001b[0;36mpygcgopt.gcg.PartialDecomposition._PartialDecomposition__generate_visualization\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/pygcgopt/decomposition.pxi:1425\u001b[0m, in \u001b[0;36mpygcgopt.gcg.PartialDecomposition._PartialDecomposition__generate_visualization\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/gcg-env/lib/python3.8/pathlib.py:1236\u001b[0m, in \u001b[0;36mPath.read_text\u001b[0;34m(self, encoding, errors)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;124;03m    Open the file in text mode, read it, and close the file.\u001b[39;00m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1236\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1237\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/miniconda3/envs/gcg-env/lib/python3.8/pathlib.py:1222\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_closed()\n\u001b[0;32m-> 1222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m               \u001b[49m\u001b[43mopener\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gcg-env/lib/python3.8/pathlib.py:1078\u001b[0m, in \u001b[0;36mPath._opener\u001b[0;34m(self, name, flags, mode)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_opener\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, flags, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0o666\u001b[39m):\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# A stub for the opener argument to built-in open()\u001b[39;00m\n\u001b[0;32m-> 1078\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/tmplxh7_wqc/vis.svg'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: gnuplot: not found\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/tmp8y_rajlu/vis.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/gcg-env/lib/python3.8/site-packages/IPython/core/formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    342\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32msrc/pygcgopt/decomposition.pxi:1398\u001b[0m, in \u001b[0;36mpygcgopt.gcg.PartialDecomposition._repr_png_\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/pygcgopt/decomposition.pxi:1406\u001b[0m, in \u001b[0;36mpygcgopt.gcg.PartialDecomposition._PartialDecomposition__generate_visualization\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/pygcgopt/decomposition.pxi:1427\u001b[0m, in \u001b[0;36mpygcgopt.gcg.PartialDecomposition._PartialDecomposition__generate_visualization\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/gcg-env/lib/python3.8/pathlib.py:1229\u001b[0m, in \u001b[0;36mPath.read_bytes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;124;03m    Open the file in bytes mode, read it, and close the file.\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1229\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/miniconda3/envs/gcg-env/lib/python3.8/pathlib.py:1222\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_closed()\n\u001b[0;32m-> 1222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m               \u001b[49m\u001b[43mopener\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gcg-env/lib/python3.8/pathlib.py:1078\u001b[0m, in \u001b[0;36mPath._opener\u001b[0;34m(self, name, flags, mode)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_opener\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, flags, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0o666\u001b[39m):\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# A stub for the opener argument to built-in open()\u001b[39;00m\n\u001b[0;32m-> 1078\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/tmp8y_rajlu/vis.png'"
     ]
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the simple \"d\" line with:\n",
    "print(\"Decomposition visualization:\")\n",
    "print(f\"Number of blocks: {d.getNBlocks()}\")\n",
    "print(f\"Number of master constraints: {d.getNMasterconss()}\")\n",
    "print(f\"Number of linking variables: {d.getNLinkingvars()}\")\n",
    "print(f\"Scores:\")\n",
    "print(f\"  Classic score: {d.classic_score:.04f}\")\n",
    "print(f\"  Border area score: {d.border_area_score:.04f}\")\n",
    "print(f\"  Max white score: {d.max_white_score:.04f}\")\n",
    "print(f\"  Max for white score: {d.max_for_white_score:.04f}\")\n",
    "\n",
    "# Show block information\n",
    "for block in range(d.getNBlocks()):\n",
    "    print(f\"\\nBlock {block}:\")\n",
    "    print(f\"  Number of constraints: {d.getNConssForBlock(block)}\")\n",
    "    print(f\"  Number of variables: {d.getNVarsForBlock(block)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb3d799",
   "metadata": {},
   "source": [
    "### Selecting Decompositions\n",
    "After this investigation, we decide that we like this particular decomposition. The following code orders GCG to select our decomposition instead of an automatic one. Then, the optimization process is started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "further-curtis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A Dantzig-Wolfe reformulation is applied to solve the original problem.\n",
      "Chosen structure has 50 blocks and 51 linking constraints.\n",
      "This decomposition has a maxwhite score of 0.485149.\n",
      "Matrix has 50 blocks, using 50 pricing problems.\n",
      "\n",
      "  time | node  | left  |SLP iter|MLP iter|LP it/n| mem |mdpt |ovars|mvars|ocons|mcons|mcuts|  dualbound   | primalbound  |  deg   |  gap   \n",
      "p  0.2s|     1 |     0 |      0 |      0 |     - |  36M|   0 |2550 |   0 | 102 |   0 |   0 | 0.000000e+00 | 2.711000e+03 |   --   |    Inf \n",
      "p  0.2s|     1 |     0 |      0 |      0 |     - |  36M|   0 |2550 |   0 | 102 |   0 |   0 | 0.000000e+00 | 1.785000e+03 |   --   |    Inf \n",
      "p  0.2s|     1 |     0 |      0 |      0 |     - |  36M|   0 |2550 |   0 | 102 |   0 |   0 | 0.000000e+00 | 1.102000e+03 |   --   |    Inf \n",
      "   0.2s|     1 |     0 |      0 |      0 |     - |  36M|   0 |2550 |   0 | 102 |   0 |   0 | 0.000000e+00 | 1.102000e+03 |   --   |    Inf \n",
      "\n",
      "     \n",
      "   0.2s|     1 |     0 |      0 |      0 |     - |  36M|   0 |2550 |  50 | 102 | 102 |   0 | 0.000000e+00 | 1.102000e+03 |   0.00%|    Inf    0.2s|     1 |     0 |      0 |      0 |     - |  36M|   0 |2550 | 150 | 102 | 102 |   0 | 0.000000e+00 | 1.102000e+03 |   0.00%|    Inf \n",
      "\n",
      "Starting reduced cost pricing...\n",
      "   0.4s|     1 |     0 |   2081 |   2081 |     - |  44M|   0 |2550 |1699 | 102 | 102 |   0 | 7.050000e+02 | 1.102000e+03 |  36.95%|  56.31%\n",
      "X  1.3s|     1 |     0 |   3055 |   3055 |     - |  55M|   0 |2550 |1749 | 102 | 102 |   0 | 7.050000e+02 | 8.150000e+02 |  36.95%|  15.60%\n",
      "Y  1.4s|     1 |     0 |   3055 |   3055 |     - |  55M|   0 |2550 |1799 | 102 | 102 |   0 | 7.050000e+02 | 7.580000e+02 |  36.95%|   7.52%\n",
      "   1.4s|     1 |     0 |   3055 |   3055 |     - |  55M|   0 |2550 |1799 | 102 | 102 |   0 | 7.050000e+02 | 7.580000e+02 |  36.95%|   7.52%\n",
      "   1.4s|     1 |     0 |   3055 |   3055 |     - |  55M|   0 |2550 |1799 | 102 | 102 |   0 | 7.050000e+02 | 7.580000e+02 |  36.95%|   7.52%\n",
      "   1.4s|     1 |     0 |   3055 |   3055 |     - |  55M|   0 |2550 |1799 | 102 | 102 |   0 | 7.050000e+02 | 7.580000e+02 |  36.95%|   7.52%\n",
      "   1.4s|     1 |     2 |   3055 |   3055 |     - |  55M|   0 |2550 |1799 | 102 | 102 |   0 | 7.050000e+02 | 7.580000e+02 |  36.95%|   7.52%\n",
      "*r 2.4s|     6 |     5 |   4384 |   4384 | 327.4 | 156M|   3 |2550 |2002 | 102 | 102 |   0 | 7.065000e+02 | 7.380000e+02 |   --   |   4.46%\n",
      "*r 2.4s|     6 |     5 |   4482 |   4482 | 347.0 | 156M|   3 |2550 |2053 | 102 | 102 |   0 | 7.065000e+02 | 7.340000e+02 |   --   |   3.89%\n",
      "  time | node  | left  |SLP iter|MLP iter|LP it/n| mem |mdpt |ovars|mvars|ocons|mcons|mcuts|  dualbound   | primalbound  |  deg   |  gap   \n",
      "*r 3.7s|    21 |     8 |  10404 |  10404 | 382.9 | 159M|   5 |2550 |2270 | 102 | 102 |   0 | 7.123333e+02 | 7.150000e+02 |   --   |   0.37%\n",
      "*r 3.7s|    22 |     5 |  10466 |  10466 | 367.6 | 159M|   6 |2550 |2270 | 102 | 102 |   0 | 7.123333e+02 | 7.140000e+02 |   --   |   0.23%\n",
      "*r 3.8s|    22 |     0 |  10699 |  10699 | 378.7 | 160M|   6 |2550 |2461 | 102 | 102 |   0 | 7.123333e+02 | 7.130000e+02 |   --   |   0.09%\n",
      "\n",
      "SCIP Status        : problem is solved [optimal solution found]\n",
      "Solving Time (sec) : 3.82\n",
      "Solving Nodes      : 22\n",
      "Primal Bound       : +7.13000000000000e+02 (11 solutions)\n",
      "Dual Bound         : +7.13000000000000e+02\n",
      "Gap                : 0.00 %\n"
     ]
    }
   ],
   "source": [
    "d.isSelected = True\n",
    "\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f846322a",
   "metadata": {},
   "source": [
    "## Use-Case 3: Building a custom Decomposition\n",
    "In the previous use-cases we run GCG with automatically detected decompositions. This is useful if we do not know the exact structure of a model but still want to exploit GCG's decomposition approach.\n",
    "\n",
    "However, for our model we *do* know its structure. If you take another look at our `build_model()` method, you will notice that we store the created constraints in different variables based on their type. This is a typical approach when we want to specify a custom decomposition after building the model using the Python interface.\n",
    "\n",
    "In the following code, we recreate our model and use the different constraint types fo select constraints for reformulation and constraints for the Dantzig-Wolfe master problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "478b6cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCG version 3.6.2 [GitHash: NoGitInfo]\n",
      "Copyright (C) 2010-2024 Operations Research, RWTH Aachen University\n",
      "                        Konrad-Zuse-Zentrum fuer Informationstechnik Berlin (ZIB)\n",
      "\n",
      "SCIP version 9.1.1 [precision: 8 byte] [memory: block] [mode: optimized] [LP solver: Soplex 7.1.1] [GitHash: NoGitInfo]\n",
      "Copyright (c) 2002-2024 Zuse Institute Berlin (ZIB)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'pygcgopt.gcg.Model' object has no attribute 'createPartialDecomposition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m conss_master \u001b[38;5;241m=\u001b[39m conss_assignment \u001b[38;5;241m+\u001b[39m [cons_pmedian]\n\u001b[1;32m      6\u001b[0m conss_reform \u001b[38;5;241m=\u001b[39m conss_capacity\n\u001b[0;32m----> 8\u001b[0m pd \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreatePartialDecomposition\u001b[49m()\n\u001b[1;32m      9\u001b[0m pd\u001b[38;5;241m.\u001b[39mfixConssToMaster(conss_master)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(conss_reform):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'pygcgopt.gcg.Model' object has no attribute 'createPartialDecomposition'"
     ]
    }
   ],
   "source": [
    "m, conss_assignment, conss_capacity, cons_pmedian = build_model(\n",
    "    n_locations, n_clusters, distances, demands, capacities\n",
    ")\n",
    "\n",
    "conss_master = conss_assignment + [cons_pmedian]\n",
    "conss_reform = conss_capacity\n",
    "\n",
    "pd = m.createPartialDecomposition()\n",
    "pd.fixConssToMaster(conss_master)\n",
    "\n",
    "for block, c in enumerate(conss_reform):\n",
    "    pd.fixConsToBlock(c, block)\n",
    "\n",
    "# m.addPreexistingPartialDecomposition(pd)\n",
    "\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, conss_assignment, conss_capacity, cons_pmedian = build_model(\n",
    "    n_locations, n_clusters, distances, demands, capacities\n",
    ")\n",
    "\n",
    "try:\n",
    "    pd = m.createPartialDecomposition()\n",
    "    \n",
    "    # Use fixConssToMaster instead of addConsToMaster\n",
    "    pd.fixConssToMaster(conss_assignment + [cons_pmedian])\n",
    "    \n",
    "    # Use fixConsToBlock instead of addConsToBlock\n",
    "    for block, cons in enumerate(conss_capacity):\n",
    "        pd.fixConsToBlock(cons, block)\n",
    "    \n",
    "    # Set decomposition\n",
    "    m.addPreexistingPartialDecomposition(pd)\n",
    "    m.optimize()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error in custom decomposition: {str(e)}\")\n",
    "    print(\"Falling back to automatic decomposition\")\n",
    "    m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d89973",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "With that, we have seen the most important features to use GCG as a solver through the Python interface. In a different example, we will take a look at how GCG can be extended using Python code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcg-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "metadata": {
   "interpreter": {
    "hash": "96c411c10837af9498e15621947793a2592cd914a8b21febdb89cd6ff87a6197"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
